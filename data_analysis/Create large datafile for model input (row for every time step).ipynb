{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import numpy as np\n",
    "from scipy.signal import argrelextrema\n",
    "from scipy import signal\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose Time Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.date(2017,9,1)\n",
    "end_date = datetime.date(2018,3,1)\n",
    "\n",
    "# choose to plot some data \n",
    "plot = False\n",
    "\n",
    "# usage of self-made high/low water algorithm\n",
    "extrema_algorithm = True\n",
    "\n",
    "# resolution of the data\n",
    "round_to = '30 min'\n",
    "\n",
    "# create/use pickled data set \n",
    "create_pkl = False # pkl has to created only once\n",
    "use_pickle_waterlevels = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Water level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pkl file if needed\n",
    "if create_pkl:\n",
    "    \n",
    "    # load water level data and save as pkl (saves loading time in future)\n",
    "    path = \"C:/Users/Marleen/Documents/thesis project/Data zaken/Data/Getij data/waterhoogte_Vlieland_1990_2018.csv\"\n",
    "    df_all_water_levels = pd.read_csv(path, delimiter=\",\")\n",
    "\n",
    "    # set date time to pandas timestamp \n",
    "    df_all_water_levels['date_time'] = pd.to_datetime(df_all_water_levels['date_time'], dayfirst=True)\n",
    "\n",
    "    # drop location and obstype and tijd, datum\n",
    "    df_all_water_levels = df_all_water_levels[['date_time','waterheight']]\n",
    "\n",
    "    # specify path and save\n",
    "    file_name = \"pkl_water_level_vlieland_1990_2018\"\n",
    "    path = 'C:/Users/Marleen/Documents/thesis project/Data zaken/Data/Getij data/'\n",
    "    df_all_water_levels.to_pickle(path + file_name +\".pkl\")\n",
    "\n",
    "# read pickled data set\n",
    "if use_pickle_waterlevels:\n",
    "    file_name = \"pkl_water_level_vlieland_1990_2018\"\n",
    "    path = 'C:/Users/Marleen/Documents/thesis project/Data zaken/Data/Getij data/'\n",
    "    df_all_water_levels = pd.read_pickle(path + file_name +\".pkl\")\n",
    "    \n",
    "# read original data set\n",
    "else:\n",
    "    \n",
    "    # load the water level data\n",
    "    path = \"C:/Users/Marleen/Documents/thesis project/Data zaken/Data/Getij data/Waterhoogte Vlieland gemeten per 10 minuten.csv\"\n",
    "    df_all_water_levels = pd.read_csv(path, delimiter=\";\")\n",
    "\n",
    "    # set date time to pandas timestamp \n",
    "    df_all_water_levels['date_time'] = pd.to_datetime(df_all_water_levels['date_time'])\n",
    "\n",
    "    # drop location and obstype and tijd, datum\n",
    "    df_all_water_levels = df_all_water_levels[['date_time','waterheight']]\n",
    "\n",
    "# select dates \n",
    "df_water_levels = df_all_water_levels.loc[(df_all_water_levels['date_time'].dt.date >= start_date) & (df_all_water_levels['date_time'].dt.date < end_date)]\n",
    "\n",
    "# set index and remove date_time column for now\n",
    "df_water_levels.set_index(pd.to_datetime(df_water_levels[\"date_time\"]), inplace=True)\n",
    "del df_water_levels['date_time']\n",
    "\n",
    "# add missing data with linear interpolation\n",
    "idx = pd.date_range(min(df_water_levels.index), max(df_water_levels.index), freq='10min') # this should be 10 minutes always\n",
    "df_water_levels = df_water_levels.reindex(index=idx, fill_value=np.nan)\n",
    "df_water_levels.interpolate(method='linear', inplace=True)\n",
    "\n",
    "# round the water levels to integers\n",
    "df_water_levels.waterheight = df_water_levels.waterheight.round()\n",
    "\n",
    "# only get necessary intervals\n",
    "df_water_levels = df_water_levels.resample(round_to).first()\n",
    "\n",
    "# re-order dataframe a bit\n",
    "df_water_levels['date_time'] = df_water_levels.index\n",
    "df_water_levels = df_water_levels.reset_index(drop=True)\n",
    "df_water_levels = df_water_levels[['date_time', 'waterheight']]\n",
    "\n",
    "df_water_levels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find high/low tide time stamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_double_indices(indices):\n",
    "    \"\"\" In case the arglextrema could not find the local/global maximum \n",
    "    with a suitable distance between the points, this function removes the double indices. \n",
    "    \"\"\"\n",
    "    \n",
    "    # make sure the points are distanced enough\n",
    "    indices_to_remove = []\n",
    "    minimum_dist = 20\n",
    "\n",
    "    # compare all values\n",
    "    for i in range(len(indices)):\n",
    "        for j in range(i + 1, len(indices)):\n",
    "            a = indices[i] + minimum_dist\n",
    "            if indices[j] < a:\n",
    "                indices_to_remove.append(indices[j])\n",
    "\n",
    "    # final set of values to remove\n",
    "    indices_to_remove_final = list(set(indices_to_remove))\n",
    "\n",
    "    # remove values from indices list\n",
    "    indices = list(indices)\n",
    "    for item in indices_to_remove_final:\n",
    "        indices.remove(item)\n",
    "    final_indices = indices\n",
    "    return final_indices\n",
    "\n",
    "if extrema_algorithm:\n",
    "    \n",
    "    # number of neigbours to compare, note: this is dependent on time step size \n",
    "    # also note: the outcome of the algorithm is very dependent on this value, so always check\n",
    "    # the high/low tide intervals\n",
    "    n = 10\n",
    "    \n",
    "    # find indices of max/min water levels in interval of n neighbours\n",
    "    indices_high = argrelextrema(df_water_levels.waterheight.values, np.greater_equal, order=n)[0]\n",
    "    indices_low = argrelextrema(df_water_levels.waterheight.values, np.less_equal, order=n)[0]\n",
    "    \n",
    "    # remove neigbouring indices due to flat extrema\n",
    "    final_indices_high = remove_double_indices(indices_high)\n",
    "    final_indices_low = remove_double_indices(indices_low)\n",
    "    \n",
    "    # add column with extrema\n",
    "    df_water_levels_tides = df_water_levels\n",
    "    df_water_levels_tides['extreem'] = np.nan\n",
    "    df_water_levels_tides['extreem'].iloc[final_indices_high] = 'HW' \n",
    "    df_water_levels_tides['extreem'].iloc[final_indices_low] = 'LW'\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # load the tide data\n",
    "    path = \"C:/Users/Marleen/Documents/thesis project/Data zaken/Data/Getij data/Tijden Hoogwater en Laagwater Vlieland vanaf 2016.csv\"\n",
    "    df_tide_times = pd.read_csv(path, delimiter=\";\")\n",
    "\n",
    "    # remove unnessary columns\n",
    "    df_tide_times = df_tide_times[['date_time', 'waterhoogte', 'extreem']]\n",
    "\n",
    "    # set date time to pandas timestamp \n",
    "    df_tide_times['date_time'] = pd.to_datetime(df_tide_times['date_time'])\n",
    "\n",
    "    # select dates \n",
    "    df_tide_times = df_tide_times.loc[(df_tide_times['date_time'].dt.date >= start_date) & (df_tide_times['date_time'].dt.date < end_date)]\n",
    "\n",
    "    # transform data from europe time to UTC\n",
    "    df_tide_times['date_time'] = df_tide_times['date_time'].dt.tz_localize('Europe/London').dt.tz_convert('UTC')\n",
    "\n",
    "    # round timestamps to intervals of 10 minutes\n",
    "    df_tide_times['date_time'] = df_tide_times['date_time'].dt.round(round_to) \n",
    "       \n",
    "    # convert to same date time format as water levels data\n",
    "    df_tide_times['date_time'] = df_tide_times['date_time'].values.astype('datetime64[ns]')\n",
    "\n",
    "    # perform left join on date time\n",
    "    df_water_levels_tides = pd.merge(df_water_levels, df_tide_times[['date_time','extreem']], how='left', on='date_time')\n",
    "\n",
    "# make sure the data set starts and ends at high water\n",
    "df_water_levels_tides = df_water_levels_tides.iloc[(df_water_levels_tides['extreem'] == 'HW').values.argmax():]\n",
    "df_water_levels_tides = df_water_levels_tides.loc[:(df_water_levels_tides[df_water_levels_tides['extreem'] == 'HW']).last_valid_index()]\n",
    "\n",
    "# create df with high/low water points \n",
    "df_high_water = df_water_levels_tides[df_water_levels_tides['extreem'] == 'HW']\n",
    "df_low_water = df_water_levels_tides[df_water_levels_tides['extreem'] == 'LW']\n",
    "\n",
    "# create a plot with water levels and high/low tide points\n",
    "plt.plot(df_water_levels['date_time'], df_water_levels['waterheight'])\n",
    "plt.plot(df_high_water.date_time, df_high_water.waterheight, 'ro')\n",
    "plt.plot(df_low_water.date_time, df_low_water.waterheight, 'go')\n",
    "\n",
    "df_water_levels_tides.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the length of the tidal cycle and the length until low tide\n",
    "\n",
    "For every tidal cycle we want to know how long the cycle lasts (from high tide to the next high tide) and also the time it takes before low tide is reached (from high tide to low tide).\n",
    "\n",
    "The time between tidal cycles is calculated as the number of steps per tidal cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create extra column in df\n",
    "df_water_levels_tides['time_steps_in_cycle'] = np.nan\n",
    "df_water_levels_tides['time_steps_to_low_tide'] = np.nan\n",
    "\n",
    "# get all indices with high water (easy now, see above code block)\n",
    "high_water_indices = (df_water_levels_tides[df_water_levels_tides['extreem'] == 'HW']).index\n",
    "low_water_indices =  (df_water_levels_tides[df_water_levels_tides['extreem'] == 'LW']).index\n",
    "\n",
    "# number of time steps between high tides\n",
    "num_time_steps_high_tides = np.diff(high_water_indices)\n",
    "\n",
    "# calculate time steps till low tide \n",
    "print(len(low_water_indices), len(high_water_indices))\n",
    "time_steps_to_low_tide = low_water_indices - high_water_indices[:-1]  \n",
    "\n",
    "# couple number of time steps to high water time points (exclude the last one, since this point is the end of the simulation)\n",
    "df_water_levels_tides.time_steps_in_cycle.loc[high_water_indices[:-1]] = num_time_steps_high_tides\n",
    "\n",
    "# also add number of time steps to low tide for every high tide\n",
    "df_water_levels_tides.time_steps_to_low_tide.loc[high_water_indices[:-1]] = time_steps_to_low_tide\n",
    "\n",
    "# df_water_levels_tides[(df_water_levels_tides['extreem'] == 'HW') | (df_water_levels_tides['extreem'] == 'LW')]\n",
    "df_water_levels_tides.head()\n",
    "\n",
    "# check if intervals make sense\n",
    "print(max(df_water_levels_tides.time_steps_in_cycle), min(df_water_levels_tides.time_steps_in_cycle))\n",
    "print(max(df_water_levels_tides.time_steps_to_low_tide), min(df_water_levels_tides.time_steps_to_low_tide))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_water_levels_tides[df_water_levels_tides.time_steps_in_cycle == 29]\n",
    "df_water_levels_tides[df_water_levels_tides.time_steps_in_cycle == 28]\n",
    "df_water_levels_tides[df_water_levels_tides.time_steps_to_low_tide == 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick plot to check if max and min tidal cycle lengths are correct\n",
    "date = datetime.date(2016,11,20)\n",
    "plt.plot(df_water_levels_tides.waterheight[df_water_levels_tides.date_time.dt.date == date])\n",
    "plt.plot(df_high_water.waterheight[df_high_water.date_time.dt.date == date], 'ro')\n",
    "plt.plot(df_low_water.waterheight[df_low_water.date_time.dt.date == date], 'go')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert the reference weight data\n",
    "\n",
    "The data has no date time yet, only the day within a year is mentioned. This day should be converted to a date time object and the data set should then be merged with the existing data set (and only on the high tide moments). \n",
    "\n",
    "Data comes from Zwart & Hulscher et al. (1996): Seasonal and Annual variation in body weight,...\n",
    "\n",
    "(Let op! Dit gedeelte moet mogelijk aangepast worden als we andere jaren simuleren en als het een schrikkeljaar is)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulation years\n",
    "start_year = start_date.year\n",
    "end_year = end_date.year\n",
    "\n",
    "# days in new year (this should be 31 + 29 als schrikkeljaar)\n",
    "days_in_new_y = 31 + 28 # january + february\n",
    "\n",
    "# load the data\n",
    "path = \"C:/Users/Marleen/Documents/thesis project/Data zaken/Streefgewicht Scholekster.csv\"\n",
    "df_ref_weight = pd.read_csv(path, delimiter=\";\")\n",
    "\n",
    "# add all day numbers (should be 366 in case of schrikkeljaar)\n",
    "new_df = pd.DataFrame()\n",
    "new_df['day'] = range(1, 368)\n",
    "df_ref_weight = pd.merge(new_df, df_ref_weight, how='left')\n",
    "\n",
    "# interpolate to days\n",
    "df_ref_weight = df_ref_weight.interpolate(method='linear') #todo: naar 12 uur itnervals interpoleren? half uur?\n",
    "\n",
    "# last row is unnecessary (366 is the first day again)\n",
    "df_ref_weight = df_ref_weight.iloc[:-2]\n",
    "\n",
    "# add year to the data (right now for 2017/2018) \n",
    "df_ref_weight['year'] = np.where(df_ref_weight['day'] < days_in_new_y + 1, end_year, start_year)\n",
    "\n",
    "# add date time to dataframe\n",
    "df_ref_weight['date_time'] = pd.to_datetime(df_ref_weight['year'] * 1000 + df_ref_weight['day'], format='%Y%j')\n",
    "\n",
    "# merge with rest of the data set\n",
    "df_water_levels_tides_weight = pd.merge(df_water_levels_tides, df_ref_weight.weight, left_on=[df_water_levels_tides.date_time.dt.year, df_water_levels_tides.date_time.dt.month, df_water_levels_tides.date_time.dt.day],\n",
    "        right_on=[df_ref_weight.date_time.dt.year, df_ref_weight.date_time.dt.month, df_ref_weight.date_time.dt.day])\n",
    "\n",
    "# plot\n",
    "if plot == True:\n",
    "    plt.plot(df_water_levels_tides_weight.date_time, df_water_levels_tides_weight.weight)\n",
    "    plt.title('Reference Weight')\n",
    "\n",
    "# set non HW rows to np.nan (niet zo netjes zo)\n",
    "df_water_levels_tides_weight.weight.loc[df_water_levels_tides_weight.extreem != \"HW\"] = np.nan\n",
    "\n",
    "# remove key columns (kan netter)\n",
    "df_water_levels_tides_weight = df_water_levels_tides_weight[['date_time', 'waterheight', 'extreem', 'time_steps_in_cycle', 'time_steps_to_low_tide', 'weight']]\n",
    "\n",
    "# change name for convenience\n",
    "df_final = df_water_levels_tides_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[df_final.extreem==\"HW\"].iloc[230:240]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert the temperature data\n",
    "\n",
    "The temperature data should be coupled to the tidal cycles, ideally we choose the average daily temperature in which most of the cycle is located. Another possibility would be to simply get the temperature at the start of the cycle (implementation would be easier then).\n",
    "\n",
    "For now: just take the temperature at the start of the cycle, if time is left we can change this. Note that this makes the data look a bit more \"coarse\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "path = \"C:/Users/Marleen/Documents/thesis project/Data zaken/Data/KNMI data/Weergegevens KNMI Vlieland.csv\"\n",
    "df_temperature = pd.read_csv(path, delimiter=\",\")\n",
    "\n",
    "# only keep temperature and day/time columns\n",
    "df_temperature = df_temperature[['YYYYMMDD', '    T']]\n",
    "\n",
    "# change column names\n",
    "df_temperature.columns = ['date', 'temperature']\n",
    "\n",
    "# set date time to pandas timestamp \n",
    "df_temperature['date_time'] = pd.to_datetime(df_temperature['date'], format='%Y%m%d')\n",
    "df_temperature = df_temperature[['date_time', 'temperature']]\n",
    "\n",
    "# get part of the data we want\n",
    "df_temperature = df_temperature[(df_temperature.date_time.dt.date >= start_date) & (df_temperature.date_time.dt.date < end_date)]\n",
    "\n",
    "# convert to floats\n",
    "df_temperature.temperature = df_temperature.temperature.astype(float)\n",
    "\n",
    "# # get mean temperature per day\n",
    "df_temperature_means = df_temperature.groupby('date_time').mean()\n",
    "df_temperature_means['date_time'] = df_temperature_means.index \n",
    "df_temperature_means = df_temperature_means.reset_index(drop=True)\n",
    "\n",
    "# change temperature to degrees celcius (instead of 0.1 degrees celcius)\n",
    "df_temperature_means.temperature = df_temperature_means.temperature / 10\n",
    "\n",
    "# couple with final df\n",
    "df_final = pd.merge(df_final, df_temperature_means, \n",
    "                    left_on=[df_final.date_time.dt.year, df_final.date_time.dt.month, df_final.date_time.dt.day],\n",
    "                    right_on=[df_temperature_means.date_time.dt.year, \n",
    "                              df_temperature_means.date_time.dt.month, \n",
    "                              df_temperature_means.date_time.dt.day])\n",
    "\n",
    "# grab final columns (keys are in there now)\n",
    "df_final = df_final[['date_time_x', 'waterheight', 'extreem', 'time_steps_in_cycle', \n",
    "                     'time_steps_to_low_tide', 'weight', 'temperature']]\n",
    "df_final=df_final.rename(columns = {'date_time_x':'date_time'})\n",
    "\n",
    "# plot to check if data is logical\n",
    "if plot == True:\n",
    "    plt.plot(df_final.date_time, df_final.temperature)\n",
    "\n",
    "# set temperature of non HW rows to zero\n",
    "df_final.temperature.loc[df_final.extreem != \"HW\"] = np.nan\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(df_final.time_steps_to_low_tide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Cockle Fresh Weight Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "path = \"C:/Users/Marleen/Documents/thesis project/Data zaken/Data/Voedsel data/Cockle_Fresh_Weight_Change.csv\"\n",
    "df_cockle_change = pd.read_csv(path, delimiter=\";\")\n",
    "\n",
    "# add day of year\n",
    "df_cockle_change['day_in_year'] = (df_cockle_change.Year_Time * 365 + 1) % 365\n",
    "\n",
    "# round to day\n",
    "df_cockle_change.day_in_year = df_cockle_change.day_in_year.round()\n",
    "\n",
    "# divide wet weight change in 1 and 2 year cockle groups\n",
    "df_cockle_change_1y = df_cockle_change[(df_cockle_change.Year_Time > 0.5) & (df_cockle_change.Year_Time < 1.5)]\n",
    "df_cockle_change_2y = df_cockle_change[(df_cockle_change.Year_Time > 1.5) & (df_cockle_change.Year_Time < 2.5)]\n",
    "\n",
    "# add correct years to dataframes\n",
    "df_cockle_change_1y['year'] = np.where(df_cockle_change_1y['day_in_year'] < 200, end_date.year, start_date.year)\n",
    "df_cockle_change_2y['year'] = np.where(df_cockle_change_2y['day_in_year'] < 200, end_date.year, start_date.year)\n",
    "\n",
    "# create date time with day_in_year and year to date time\n",
    "df_cockle_change_1y['date_time'] = pd.to_datetime(df_cockle_change_1y['year'] * 1000 + df_cockle_change_1y['day_in_year'], \n",
    "                                                  format='%Y%j')\n",
    "df_cockle_change_2y['date_time'] = pd.to_datetime(df_cockle_change_2y['year'] * 1000 + df_cockle_change_2y['day_in_year'], \n",
    "                                                  format='%Y%j')\n",
    "\n",
    "# rename growth columns\n",
    "df_cockle_change_1y.rename(columns = {'Growth':'1y_fw_cockle_growth'}, inplace=True)\n",
    "df_cockle_change_2y.rename(columns = {'Growth':'2y_fw_cockle_growth'}, inplace=True)\n",
    "\n",
    "# create intervals and interpolate\n",
    "new_df = pd.DataFrame()\n",
    "new_df['date_time'] = pd.date_range(start=df_cockle_change_1y.date_time.iloc[0], end=df_cockle_change_1y.date_time.iloc[-1],\n",
    "                                   freq='min')\n",
    "df_cockles = pd.merge(new_df, df_cockle_change_1y[['date_time','1y_fw_cockle_growth']], how='left')\n",
    "df_cockles = pd.merge(df_cockles, df_cockle_change_2y[['date_time','2y_fw_cockle_growth']], how='left')\n",
    "\n",
    "# interpolate growth rates\n",
    "df_cockles['1y_fw_cockle_growth'] = df_cockles['1y_fw_cockle_growth'].interpolate(method='linear')\n",
    "df_cockles['2y_fw_cockle_growth'] = df_cockles['2y_fw_cockle_growth'].interpolate(method='linear')\n",
    "\n",
    "# add new column to new df\n",
    "# df_final['1y_cockle_growth'] = np.nan\n",
    "# df_final['2y_cockle_growth'] = np.nan\n",
    "\n",
    "# merge with data \n",
    "df_final = pd.merge(df_final, df_cockles[['date_time','1y_fw_cockle_growth', '2y_fw_cockle_growth']], \n",
    "                    how='left', on='date_time')\n",
    "\n",
    "# set growth on non HW points to nan\n",
    "df_final['1y_fw_cockle_growth'].loc[df_final.extreem != 'HW'] = np.nan\n",
    "df_final['2y_fw_cockle_growth'].loc[df_final.extreem != 'HW'] = np.nan\n",
    "\n",
    "# convert cockle growth/year to cockle growth per cycle\n",
    "if round_to == '30 min':\n",
    "    conversion_year_30min = 365 * 48 \n",
    "    df_final['1y_fw_cockle_growth'] = (df_final['1y_fw_cockle_growth'] / conversion_year_30min) * df_final.time_steps_in_cycle\n",
    "    df_final['2y_fw_cockle_growth'] = (df_final['2y_fw_cockle_growth'] / conversion_year_30min) * df_final.time_steps_in_cycle\n",
    "    \n",
    "# formula in model then is start_weight += (start_weight * (growth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add wet weight change for cockles\n",
    "\n",
    "As for the fresh weight, we again have a relative growth rate. Note that the mj cockles follow the same change in wtw as the 2y cockles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for relative growth and afdw from webtics & klepper1989\n",
    "def relative_growth_wtw_cockles(t):\n",
    "    afdw = 0.0136285 * np.exp(((5.13146 * t) / (1.28867 + t)) + 0.59952 * np.sin(3.05164 + 2 * np.pi * t))\n",
    "    rel_g_r =  ((6.61274  / ((1.28867 + t) ** 2)) + 3.76689 * np.cos(3.05164 + 2 * np.pi * t))\n",
    "    return afdw, rel_g_r\n",
    "\n",
    "# create data with relative growth for every day \n",
    "time_since_birth = np.arange(0, 2.5, 1/365)\n",
    "rel_gr = [relative_growth_wtw_cockles(t)[1] for t in time_since_birth]\n",
    "new_df = pd.DataFrame()\n",
    "new_df['Year_Time'] = time_since_birth\n",
    "new_df['Growth_Rate_Year'] = rel_gr\n",
    "new_df['day_in_year'] = (new_df['Year_Time'] * 365 + 1) % 365\n",
    "\n",
    "# (df_cockle_change.Year_Time * 365 + 1) % 365\n",
    "\n",
    "# divide wet weight change in 1 and 2 year cockle groups\n",
    "df_cockle_wtw_change_1y = new_df[(new_df.Year_Time > 0.5) & (new_df.Year_Time < 1.5)]\n",
    "df_cockle_wtw_change_2y = new_df[(new_df.Year_Time > 1.5) & (new_df.Year_Time < 2.5)]\n",
    "# print(df_cockle_wtw_change_1y)\n",
    "# add correct years to dataframes\n",
    "df_cockle_wtw_change_1y['year'] = np.where((df_cockle_wtw_change_1y['day_in_year'] < 184), end_date.year, start_date.year)\n",
    "df_cockle_wtw_change_2y['year'] = np.where(df_cockle_wtw_change_2y['day_in_year'] < 184, end_date.year, start_date.year)\n",
    "\n",
    "# new_df\n",
    "\n",
    "# create date time with day_in_year and year to date time\n",
    "df_cockle_wtw_change_1y['date_time'] = pd.to_datetime(df_cockle_wtw_change_1y['year'] * 1000 + \n",
    "                                                      df_cockle_wtw_change_1y['day_in_year'] + 1, format='%Y%j',\n",
    "                                                     errors='coerce')\n",
    "df_cockle_wtw_change_2y['date_time'] = pd.to_datetime(df_cockle_wtw_change_2y['year'] * 1000 + \n",
    "                                                      df_cockle_wtw_change_2y['day_in_year'] + 1, format='%Y%j',\n",
    "                                                     errors='coerce')\n",
    "# rename growth columns\n",
    "df_cockle_wtw_change_1y.rename(columns = {'Growth_Rate_Year':'1y_wtw_cockle_growth'}, inplace=True)\n",
    "df_cockle_wtw_change_2y.rename(columns = {'Growth_Rate_Year':'2y_wtw_cockle_growth'}, inplace=True)\n",
    "\n",
    "# create intervals and interpolate\n",
    "new_df = pd.DataFrame()\n",
    "new_df['date_time'] = pd.date_range(start=df_cockle_wtw_change_1y.date_time.iloc[0], \n",
    "                                    end=df_cockle_wtw_change_1y.date_time.iloc[-1], freq='min')\n",
    "df_wtw_cockles = pd.merge(new_df, df_cockle_wtw_change_1y[['date_time','1y_wtw_cockle_growth']], how='left')\n",
    "df_wtw_cockles = pd.merge(df_wtw_cockles, df_cockle_wtw_change_2y[['date_time','2y_wtw_cockle_growth']], how='left')\n",
    "\n",
    "# interpolate growth rates\n",
    "df_wtw_cockles['1y_wtw_cockle_growth'] = df_wtw_cockles['1y_wtw_cockle_growth'].interpolate(method='linear')\n",
    "df_wtw_cockles['2y_wtw_cockle_growth'] = df_wtw_cockles['2y_wtw_cockle_growth'].interpolate(method='linear')\n",
    "\n",
    "# # add new column to new df\n",
    "# df_final['1y_wtw_cockle_growth'] = np.nan\n",
    "# df_final['2y_wtw_cockle_growth'] = np.nan\n",
    "\n",
    "# merge with data \n",
    "df_final = pd.merge(df_final, df_wtw_cockles[['date_time','1y_wtw_cockle_growth', '2y_wtw_cockle_growth']], \n",
    "                    how='left', on='date_time')\n",
    "\n",
    "# set growth on non HW points to nan\n",
    "df_final['1y_wtw_cockle_growth'].loc[df_final.extreem != 'HW'] = np.nan\n",
    "df_final['2y_wtw_cockle_growth'].loc[df_final.extreem != 'HW'] = np.nan\n",
    "\n",
    "# convert wtw cockle growth/year to cockle growth per cycle\n",
    "if round_to == '30 min':\n",
    "    conversion_year_30min = 365 * 48 \n",
    "    df_final['1y_wtw_cockle_growth'] = (df_final['1y_wtw_cockle_growth'] / conversion_year_30min) * df_final.time_steps_in_cycle\n",
    "    df_final['2y_wtw_cockle_growth'] = (df_final['2y_wtw_cockle_growth'] / conversion_year_30min) * df_final.time_steps_in_cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add change in density Macoma Balthica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the dataframe \n",
    "\n",
    "The dataframe is pickled, using the to_pickle functionality of python. Pickle saves the dataframe in it's current state thus the data and its format is preserved (this is not the case if we save the df to .csv format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give file a name that indicates the time interval of the data\n",
    "file_name = \"{}_{}_{}_to_{}_{}_{}\".format(start_date.year, start_date.month, start_date.day, \n",
    "                                          end_date.year, end_date.month, end_date.day)\n",
    "\n",
    "# specify path\n",
    "path = 'C:/Users/Marleen/Documents/thesis project/oystercatcher-model/Input data/'\n",
    "\n",
    "# save!\n",
    "df_final.to_pickle(path + file_name +\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for 2018, in February and January some points are missing #### THIS PART IS REPLACED BY LINEAR INTERPOLATION ### \n",
    "# if (start_date.year == 2017) & (end_date.year == 2018):\n",
    "\n",
    "#     date_time_str = '2018-02-08 14:00:00.00000'  \n",
    "#     date_time_obj = datetime.datetime.strptime(date_time_str, '%Y-%m-%d %H:%M:%S.%f')\n",
    "#     df_water_levels = df_water_levels.append({'date_time' : date_time_obj, 'waterheight' : 43}, ignore_index=True)\n",
    "#     df_water_levels = df_water_levels.sort_values(by='date_time')\n",
    "    \n",
    "#     date_time_str = '2018-01-16 08:30:00.00000'  \n",
    "#     date_time_obj = datetime.datetime.strptime(date_time_str, '%Y-%m-%d %H:%M:%S.%f')\n",
    "#     df_water_levels = df_water_levels.append({'date_time' : date_time_obj, 'waterheight' : 160}, ignore_index=True)\n",
    "#     df_water_levels = df_water_levels.sort_values(by='date_time')\n",
    "    \n",
    "#     date_time_str = '2018-02-06 19:00:00.00000'  \n",
    "#     date_time_obj = datetime.datetime.strptime(date_time_str, '%Y-%m-%d %H:%M:%S.%f')\n",
    "#     df_water_levels = df_water_levels.append({'date_time' : date_time_obj, 'waterheight' : -123}, ignore_index=True)\n",
    "#     df_water_levels = df_water_levels.sort_values(by='date_time')\n",
    "\n",
    "# # convert to same date time format as water levels data\n",
    "# df_tide_times['date_time'] = df_tide_times['date_time'].values.astype('datetime64[ns]')\n",
    "\n",
    "# # perform left join on date time\n",
    "# df_water_levels_tides = pd.merge(df_water_levels, df_tide_times[['date_time','extreem']], how='left', on='date_time')\n",
    "\n",
    "# # make sure the data set starts and ends at high water\n",
    "# df_water_levels_tides = df_water_levels_tides.iloc[(df_water_levels_tides['extreem'] == 'HW').values.argmax():]\n",
    "# df_water_levels_tides = df_water_levels_tides.loc[:(df_water_levels_tides[df_water_levels_tides['extreem'] == 'HW']).last_valid_index()]\n",
    "\n",
    "# # create df with high/low water points \n",
    "# df_high_water = df_water_levels_tides[df_water_levels_tides['extreem'] == 'HW']\n",
    "# df_low_water = df_water_levels_tides[df_water_levels_tides['extreem'] == 'LW']\n",
    "  \n",
    "\n",
    "# # create a plot with water levels and high/low tide points\n",
    "# plt.plot(df_water_levels['date_time'], df_water_levels['waterheight'])\n",
    "# plt.plot(df_high_water.date_time, df_high_water.waterheight, 'ro')\n",
    "# plt.plot(df_low_water.date_time, df_low_water.waterheight, 'go')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
